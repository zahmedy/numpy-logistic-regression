{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be7f7ae",
   "metadata": {},
   "source": [
    "# Titanic Survival with Custom Logistic Regression\n",
    "Preprocess the Titanic dataset, scale features, train the NumPy-only logistic regression, and inspect the learned weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d617571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.model import LogisticRegression, StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef9d5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1309 rows with 14 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "data_path = os.path.join(\"..\", \"data\", \"titanic.csv\")\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"Loaded {df.shape[0]} rows with {df.shape[1]} columns\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e9f02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass          int64\n",
      "survived        int64\n",
      "age           float64\n",
      "sibsp           int64\n",
      "parch           int64\n",
      "fare          float64\n",
      "sex_male         bool\n",
      "embarked_Q       bool\n",
      "embarked_S       bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Basic cleaning: drop ID-like or high-missing columns, then handle missing values\n",
    "work = df.copy()\n",
    "drop_cols = [\"name\", \"ticket\", \"cabin\", \"boat\", \"body\", \"home.dest\"]\n",
    "work = work.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "# Fill missing numeric values\n",
    "for col in [\"age\", \"fare\"]:\n",
    "    if col in work.columns:\n",
    "        work[col] = work[col].fillna(work[col].median())\n",
    "\n",
    "# Fill categorical and one-hot encode\n",
    "if \"embarked\" in work.columns:\n",
    "    work[\"embarked\"] = work[\"embarked\"].fillna(work[\"embarked\"].mode()[0])\n",
    "categorical_cols = [c for c in [\"sex\", \"embarked\"] if c in work.columns]\n",
    "work = pd.get_dummies(work, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Drop any remaining rows with missing values\n",
    "work = work.dropna()\n",
    "\n",
    "print(work.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2546bb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1047, 8), (262, 8))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features and target\n",
    "y = work[\"survived\"].astype(float).values.reshape(-1, 1)\n",
    "X_df = work.drop(columns=[\"survived\"])\n",
    "feature_names = X_df.columns\n",
    "X = X_df.astype(float).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f7dcb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Loss: 1.1758\n",
      "Epoch 050 | Loss: 0.8305\n",
      "Epoch 100 | Loss: 0.6529\n",
      "Epoch 150 | Loss: 0.5648\n",
      "Epoch 200 | Loss: 0.5222\n",
      "Epoch 250 | Loss: 0.5010\n",
      "Epoch 300 | Loss: 0.4894\n",
      "Epoch 350 | Loss: 0.4823\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = LogisticRegression(\n",
    "    n_features=X_train.shape[1],\n",
    "    lr=0.05,\n",
    "    reg_lambda=0.001,\n",
    ")\n",
    "\n",
    "epochs = 400\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    _, y_hat = model.forward(X_train)\n",
    "    loss = model.loss(y_train, y_hat)\n",
    "    dW, dB = model.backward(X_train, y_train, y_hat)\n",
    "    model.update(dW, dB)\n",
    "    losses.append(loss)\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2878cdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.774\n",
      "Test accuracy:  0.802\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "_, train_probs = model.forward(X_train)\n",
    "_, test_probs = model.forward(X_test)\n",
    "\n",
    "train_acc = model.accuracy(y_train, train_probs)\n",
    "test_acc = model.accuracy(y_test, test_probs)\n",
    "\n",
    "print(f\"Train accuracy: {train_acc:.3f}\")\n",
    "print(f\"Test accuracy:  {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31cdcc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive signals:\n",
      "  fare: 0.4395\n",
      "  parch: -0.0961\n",
      "  sibsp: -0.1760\n",
      "  embarked_Q: -0.2085\n",
      "  age: -0.2241\n",
      "Top negative signals:\n",
      "sex_male: -1.0903\n",
      "pclass: -0.3331\n",
      "embarked_S: -0.2345\n",
      "age: -0.2241\n",
      "embarked_Q: -0.2085\n"
     ]
    }
   ],
   "source": [
    "# Inspect learned weights (top positive and negative signals)\n",
    "weights = model.weights.flatten()\n",
    "ordered = np.argsort(weights)\n",
    "\n",
    "print(\"Top positive signals:\")\n",
    "for idx in ordered[-5:][::-1]:\n",
    "    print(f\"  {feature_names[idx]}: {weights[idx]:.4f}\")\n",
    "\n",
    "print(\"Top negative signals:\")\n",
    "for idx in ordered[:5]:\n",
    "    print(f\"{feature_names[idx]}: {weights[idx]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
